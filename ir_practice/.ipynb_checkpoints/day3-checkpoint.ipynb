{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfykULuLr9iq"
   },
   "source": [
    "# Information Retrieval Practice\n",
    "\n",
    "Elasticsearch is an open-source distributed search server built on top of Apache Lucene. Itâ€™s a great tool that allows to quickly build applications with full-text search capabilities. The core implementation is in Java, but it provides a nice REST interface which allows to interact with Elasticsearch from any programming language.\n",
    "\n",
    "**Note: I do not recommend you to use Google Colab for this practice, but to execute everything locally in your computer. You will need to download, install and execute ElasticSearch, which is rather tricky to do in Colab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mjo9SrQAr9iw"
   },
   "source": [
    "## Install Elastic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7W2XY03r9ix"
   },
   "source": [
    "To install elastic search download your the package for your platform from Get Elasticsearch\n",
    " in https://www.elastic.co/es/start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Din480FEr9iy"
   },
   "source": [
    "![](https://github.com/acastellanos-ie/MBD-EN-BL-ENE-2020-J-1/blob/master/ir_practice/download.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QktBQ_jYr9iy"
   },
   "source": [
    "Once downloaded, unzip the tar.gz file and run `bin/elasticsearch` (or `bin\\elasticsearch.bat` on Windows). This will launch the ElasticSearch Server. Once the server is running, by default it's accessible at [localhost:9200](http://localhost:9200)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwKMa87jr9iz"
   },
   "source": [
    "## Querying Elastic Search via Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DaN2SWLvr9i0"
   },
   "source": [
    "To make queries to ElasticSearch you can directly query the server endpoint via REST. However, we can make it easier via the the `elasticsearch-py` Python library. This library provides a wrapper for the REST endpoint that will allow us to query the server form Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MRzPeJmtr9i0"
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcigHW8cr9i1"
   },
   "source": [
    "# Exercise 0: Indexing and Searching Demo for ElasticSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oI2elz4or9i1"
   },
   "source": [
    "Now it's time to run some demo program. In this practice, we will create inverted index of sample documents (indexing) and then use Elasticsearch query grammar to search documents (searching)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vPilzILBr9i2"
   },
   "source": [
    "### Useful functions\n",
    "\n",
    "Functions to facilitate the reading of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Re0X2kDCr9i2"
   },
   "outputs": [],
   "source": [
    "import os, io\n",
    "from collections import namedtuple\n",
    "\n",
    "Doc = namedtuple('Doc', 'filename path text')\n",
    "\n",
    "def read_doc(doc_path, encoding):\n",
    "    '''\n",
    "        reads a document from path\n",
    "        input:\n",
    "            - doc_path : path of document\n",
    "            - encoding: encoding\n",
    "        output: =>\n",
    "            - doc: instance of Doc namedtuple\n",
    "    '''\n",
    "    filename = doc_path.split('/')[-1]\n",
    "    fp = io.open(doc_path, 'r', encoding = encoding)\n",
    "    text = fp.read().strip()\n",
    "    fp.close()\n",
    "    return Doc(filename = filename, text = text, path = doc_path)\n",
    "\n",
    "def read_dataset(path, encoding = \"ISO-8859-1\"):\n",
    "    '''\n",
    "        reads multiple documents from path\n",
    "        input:\n",
    "            - doc_path : path of document\n",
    "            - encoding: encoding\n",
    "        output: =>\n",
    "            - docs: instances of Doc namedtuple returned as generator\n",
    "    '''\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for doc_path in files:\n",
    "            yield read_doc(root + '/' + doc_path, encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hdLHrhcr9i3"
   },
   "source": [
    "## Indexing\n",
    "\n",
    "We will try to index the sample documents in `./sample_documents`. To index the documents, we first need to make a connection to **Elasticsearch**. \n",
    "\n",
    "Before we index the documents, we first need to define the **configuration of elasticsearch**. During this process, you can define basic configuration of indexer such as tokenizer, stemmer, lemmatizer, and also define which search algorithm elasticsearch will use for search.\n",
    "\n",
    "Below code shows a simple configuration settings for this demo.\n",
    "The configuration tells elasticsearch that our document `doc` will have three fields `filename`, `path`, and `text`, and we will use `text` field for search. `my_analyzer` will be used to parse the `text` field, and `my_analyzer` will also be used as a search analyzer, which will parse search queries later on. `index:False` in `filename` and `path` fields tell elasticsearch that we will not index these two fields, therefore, we cannot search these two fields with queries. \n",
    "\n",
    "The detailed documentation of analyzer can be found [here](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis.html).\n",
    "\n",
    "`\"similarity\": \"boolean\"` in `text` field will let elasticsearch know that we will use a boolean search algorithm to search `text` field. The detailed documentation of search algorithms can be found [here](https://www.elastic.co/guide/en/elasticsearch/reference/current/search.html)  and [here](https://www.elastic.co/guide/en/elasticsearch/guide/master/search-in-depth.html). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DVomwD3Tr9i3"
   },
   "outputs": [],
   "source": [
    "# configuration for indexing\n",
    "settings = {\n",
    "  \"mappings\": {\n",
    "      \"properties\": {\n",
    "        \"filename\": {\n",
    "          \"type\": \"keyword\",\n",
    "          \"index\": False,\n",
    "        },\n",
    "        \"path\": {\n",
    "          \"type\": \"keyword\",\n",
    "          \"index\": False,\n",
    "        },\n",
    "        \"text\": {\n",
    "          \"type\": \"text\",\n",
    "          \"similarity\": \"boolean\",\n",
    "          \"analyzer\": \"my_analyzer\",\n",
    "          \"search_analyzer\": \"my_analyzer\"\n",
    "        }\n",
    "      }\n",
    "  },    \n",
    "  \"settings\": {      \n",
    "    \"analysis\": {\n",
    "      \"analyzer\": {\n",
    "        \"my_analyzer\": {\n",
    "          \"filter\": [\n",
    "            \"lowercase\",\"stop\"\n",
    "          ],\n",
    "          \"type\": \"custom\",\n",
    "          \"tokenizer\": \"whitespace\",\n",
    "          \"char_filter\": [\"my_char_filter\"]\n",
    "        }\n",
    "      },\n",
    "      \"char_filter\": {\n",
    "        \"my_char_filter\": {\n",
    "          \"type\": \"html_strip\",\n",
    "          \"escaped_tags\": [\"b\"]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_n65DXdr9i4"
   },
   "source": [
    "Now we will retrieve `sample documents` and indexing them into `INDEX_NAME` index. To that end, the following 2 functions will help you in the creation of the index and the indexing of the documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5,
     22
    ],
    "id": "dOzNwl6-r9i5",
    "outputId": "413664f6-1f39-4558-9f7a-a5deef201c3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index `sample_index` deleted\n",
      "index `sample_index` created\n",
      "indexed 5 docs to index `sample_index`, failed to index 0 docs\n"
     ]
    }
   ],
   "source": [
    "ES_HOSTS = ['http://localhost:9200']\n",
    "INDEX_NAME = 'sample_index'\n",
    "DOCS_PATH = 'practice_data/sample_documents'\n",
    "\n",
    "def create_index(es_conn, index_name, settings):\n",
    "    '''\n",
    "        create index structure in elasticsearch server. \n",
    "        If index_name exists in the server, it will be removed, and new index will be created.\n",
    "        input:\n",
    "            - es_conn: elasticsearch connection object\n",
    "            - index_name: name of index to create\n",
    "            - settings: settings and mappings for index to create\n",
    "        output: =>\n",
    "            - None\n",
    "    '''\n",
    "    if es_conn.indices.exists(index_name):\n",
    "        es_conn.indices.delete(index = index_name)\n",
    "        print('index `{}` deleted'.format(index_name))\n",
    "    es_conn.indices.create(index = index_name, body = settings)\n",
    "    print('index `{}` created'.format(index_name))            \n",
    "            \n",
    "def build_index(es_conn, dataset, index_name, settings, DOC_TYPE='doc'):\n",
    "    '''\n",
    "        build index from a collection of documents\n",
    "        input:\n",
    "            - es_conn: elasticsearch connection object\n",
    "            - dataset: iterable, collection of namedtuple Doc objects\n",
    "            - index_name: name of the index where the documents will be stored\n",
    "            - DOC_TYPE: type signature of documents\n",
    "    '''\n",
    "    # create the index if it doesn't exist\n",
    "    create_index(es_conn = es_conn, index_name = index_name, settings=settings)\n",
    "    counter_read, counter_idx_failed = 0, 0 # counters\n",
    "\n",
    "    # retrive & index documents\n",
    "    for doc in dataset:\n",
    "        res = es_conn.index(\n",
    "            index = index_name,\n",
    "            id = doc.filename,\n",
    "            body = doc._asdict())\n",
    "        counter_read += 1\n",
    "\n",
    "        if res['result'] != 'created':\n",
    "            counter_idx_failed += 1\n",
    "        elif counter_read % 500 == 0:\n",
    "            print('indexed {} documents'.format(counter_read))\n",
    "\n",
    "    print('indexed {} docs to index `{}`, failed to index {} docs'.format(\n",
    "        counter_read,\n",
    "        index_name,\n",
    "        counter_idx_failed\n",
    "    ))\n",
    "    \n",
    "    # refresh after indexing\n",
    "    es_conn.indices.refresh(index=index_name)  \n",
    "\n",
    "es_conn = Elasticsearch(ES_HOSTS)\n",
    "dataset = read_dataset(DOCS_PATH)\n",
    "build_index(es_conn, dataset, INDEX_NAME, settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znwKky7Vr9i7"
   },
   "source": [
    "We successfully created an inverted index for the sample documents in `./sample/documents`. It's time to search the documents with some queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqVRpkSqr9i7"
   },
   "source": [
    "## Searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaU0CUjZr9i7"
   },
   "source": [
    "**Elasticsearch** supports a specific query grammar which intends to replicate the grammar of traditional search engines (Google Search supports a similar grammar).\n",
    "https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html\n",
    "\n",
    "To understand score of the result, check: https://www.elastic.co/guide/en/elasticsearch/guide/current/relevance-intro.html#explain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5hiQ6JtCr9i8"
   },
   "source": [
    "### Useful Functions\n",
    "\n",
    "These functions will help you with the ElasticSearch output format in order to visualize the search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gwx9i3par9i8"
   },
   "outputs": [],
   "source": [
    "def extract_response(res):\n",
    "    if res is not None:\n",
    "        for hit in res['hits']['hits']:\n",
    "            filename = hit[\"_source\"][\"filename\"]\n",
    "            score = hit[\"_score\"]\n",
    "            \n",
    "            yield (filename, score)\n",
    "\n",
    "def print_result(query, res):\n",
    "    # formatter of searched result\n",
    "    matches = extract_response(res)\n",
    "    if matches is not None:\n",
    "        for match in sorted(matches, key = lambda x: -x[1]):\n",
    "            print('{}, {}, {},\\n'.format(\n",
    "                query,\n",
    "                match[0], # filename\n",
    "                match[1], # score\n",
    "            ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QweAk0s0r9i8"
   },
   "source": [
    "We will perform now different types of queries.\n",
    "\n",
    "First, a query with a single term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_sk6cNNnr9i8",
    "outputId": "1e95505c-a352-494f-df22-544efcfd4a8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama, doc1.txt, 1.0,\n",
      "\n",
      "Obama, doc3.txt, 1.0,\n",
      "\n",
      "Obama, doc5.txt, 1.0,\n",
      "\n",
      "Obama, doc2.txt, 1.0,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Boolean Query \"Obama\"\n",
    "res = es_conn.search(index = INDEX_NAME,\n",
    "    body={\n",
    "          \"query\": {\n",
    "            \"bool\": {\n",
    "              \"must\": [\n",
    "                {\n",
    "                  \"match\": {\"text\": \"Obama\"}\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    )\n",
    "print_result(\"Obama\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gD_jszWDr9i9"
   },
   "source": [
    "Now a query for the documents containing both terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QloZAGjtr9i9",
    "outputId": "b0d84445-1cd0-4062-ea21-b42770bfbf24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama AND Hillary, doc1.txt, 2.0,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Boolean Query \"Obama AND Hillary\"\n",
    "res = es_conn.search(index = INDEX_NAME,\n",
    "    body={\n",
    "          \"query\": {\n",
    "            \"match\" : {\n",
    "              \"text\" : {\n",
    "                \"query\" : \"Obama Hillary\",\n",
    "                \"operator\" : \"and\"\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    )\n",
    "print_result(\"Obama AND Hillary\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtRll956r9i-"
   },
   "source": [
    "And now containing a term but NOT the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h9rklFZpr9i-",
    "outputId": "1892c23c-799c-4c49-b91b-5b9d3d46da0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama BUT Hillary, doc3.txt, 1.0,\n",
      "\n",
      "Obama BUT Hillary, doc5.txt, 1.0,\n",
      "\n",
      "Obama BUT Hillary, doc2.txt, 1.0,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Boolean Query \"Obama BUT Hillary\"\n",
    "res = es_conn.search(index = INDEX_NAME,\n",
    "    body={\n",
    "          \"query\": {\n",
    "            \"bool\": {\n",
    "              \"must\": [\n",
    "                {\n",
    "                    \"match\": {\"text\": \"Obama\"}\n",
    "                }\n",
    "              ],\n",
    "              \"must_not\":[\n",
    "                {\n",
    "                    \"match\": {\"text\": \"Hillary\"}\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    )\n",
    "print_result(\"Obama BUT Hillary\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxqwlmlPr9i_"
   },
   "source": [
    "Finally, the default behaviour for queries with more than one term: OR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ln_kFE3Gr9i_",
    "outputId": "59860a23-5ce6-4611-87b6-ceb77ab5e07b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama OR Hillary, doc1.txt, 2.0,\n",
      "\n",
      "Obama OR Hillary, doc3.txt, 1.0,\n",
      "\n",
      "Obama OR Hillary, doc5.txt, 1.0,\n",
      "\n",
      "Obama OR Hillary, doc4.txt, 1.0,\n",
      "\n",
      "Obama OR Hillary, doc2.txt, 1.0,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Boolean Query \"Obama OR Hillary\"\n",
    "# default is OR\n",
    "res = es_conn.search(index = INDEX_NAME,\n",
    "    body={\n",
    "          \"query\": {\n",
    "            \"match\" : {\n",
    "              \"text\" : {\n",
    "                \"query\" : \"Obama Hillary\",\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    )\n",
    "print_result(\"Obama OR Hillary\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efbRto2-r9i_"
   },
   "source": [
    "# Exercise 1: Evaluating Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hc3mGuuUr9i_"
   },
   "source": [
    "We will show how the retrieved result can be evaluated by **trec_eval** evaluation program.\n",
    "\n",
    "**trec_eval** is the standard software for evaluating search engines with test collections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GS8wXQlKr9jA"
   },
   "source": [
    "## TREC_EVAL setup\n",
    "\n",
    "First, we need to install `trec_eval`. To install\n",
    "\n",
    "- go to `trec_eval-master` folder\n",
    "- run shell command `make` to create `trec_eval` binary file (If your are using Windows, you can install `make` from [here](http://gnuwin32.sourceforge.net/packages/make.htm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2OXAtADr9jA"
   },
   "source": [
    "Next, check the `government` folder which contains three things:\n",
    "\n",
    "- A set of documents needed to be indexed, in the *documents* directory.\n",
    "    \n",
    "- A set of queries, also called 'topics', in *topics/gov.topics* file. The format of **.topic* file is \"query_id query_terms\". For example, the first line of 'air.topics' file is\n",
    "    \n",
    "    `1 mining gold silver coal`\n",
    "    \n",
    "    which means that the ID of query is *01* and the corresponding query is *mining gold silver coal*.\n",
    "\n",
    "- A set of judgements, saying which documents are relevant for each query, in the *qrels/gov.qrels* file. The format of **.qrels* file is \"query_id 0 document_name binary_relevance\". For example, the first line of 'air.qrels' is\n",
    "    \n",
    "    `1 0 G00-00-0681214 0`\n",
    "    \n",
    "    which means that the document `G00-00-0681214` is not relevant to the given query id *01*. The binary relevance is *1* if the file is relevant to the query, otherwise *0*. Please ignore the second argument *0* as it is always *0*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sl2MeVRPr9jA"
   },
   "source": [
    "## Create new index\n",
    "\n",
    "In the previous exercise, we have created the index (inverted-index) of five sample documents. In this one, you will create a new index with the documents in `government/documents` folder .\n",
    "\n",
    "To build a new index, you first need to create a new index. Note that `EVAL_INDEX_NAME` should be changed in order to build separate index for the documents in `government/documents`.\n",
    "\n",
    "After creating the new configuration file, now your job is to create the new index reusing the code in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_WfSjG5r9jA"
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "  \"mappings\": {\n",
    "      \"properties\": {\n",
    "        \"filename\": {\n",
    "          \"type\": \"keyword\",\n",
    "          \"index\": False,\n",
    "        },\n",
    "        \"path\": {\n",
    "          \"type\": \"keyword\",\n",
    "          \"index\": False,\n",
    "        },\n",
    "        \"text\": {\n",
    "          \"type\": \"text\",\n",
    "          \"similarity\": \"boolean\",\n",
    "          \"analyzer\": \"my_analyzer\",\n",
    "          \"search_analyzer\": \"my_analyzer\"\n",
    "        }\n",
    "      }\n",
    "  },    \n",
    "  \"settings\": {      \n",
    "    \"analysis\": {\n",
    "      \"analyzer\": {\n",
    "        \"my_analyzer\": {\n",
    "          \"filter\": [\n",
    "            \"stop\"\n",
    "          ],\n",
    "          \"char_filter\": [\n",
    "            \"html_strip\"\n",
    "          ],\n",
    "          \"type\": \"custom\",\n",
    "          \"tokenizer\": \"whitespace\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWNwM1E2r9jB"
   },
   "source": [
    "### Exercise 1.1: Create the new index\n",
    "\n",
    "You can reuse the previous code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0AVmyXcr9jB",
    "outputId": "dcd07b7b-0de5-4e62-8dbd-45eed701edfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index `government` deleted\n",
      "index `government` created\n",
      "indexed 500 documents\n",
      "indexed 1000 documents\n",
      "indexed 1500 documents\n",
      "indexed 2000 documents\n",
      "indexed 2500 documents\n",
      "indexed 3000 documents\n",
      "indexed 3500 documents\n",
      "indexed 4000 documents\n",
      "indexed 4079 docs to index `government`, failed to index 0 docs\n"
     ]
    }
   ],
   "source": [
    "ES_HOSTS = ['http://localhost:9200']\n",
    "EVAL_INDEX_NAME = 'government'\n",
    "EVAL_DOCS_PATH = 'practice_data/government/documents'\n",
    "\n",
    "es_conn = Elasticsearch(ES_HOSTS)\n",
    "dataset = read_dataset(EVAL_DOCS_PATH)\n",
    "build_index(es_conn, dataset, EVAL_INDEX_NAME, settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSzHwK2Cr9jB"
   },
   "source": [
    "### Exercise 1.2. Read topics and produce result file\n",
    "\n",
    "Read topics (queries) from a file (`government/topics/gov.topics`) and then search documents indexed by **Elasticsearch**. You may choose one of search algorithms.\n",
    "\n",
    "Produce result file (e.g., *retrieved.txt*) according to **trec_eval** standard output format: \n",
    "\n",
    "`01 Q0 document1 0 1.23 my_IR_system1`\n",
    "\n",
    "`01 Q0 document2 1 1.08 my_IR_system1`\n",
    "\n",
    "where '01' is the query ID; ignore 'Q0'; 'documentX' is the name of the file; '0' (or '1' or some other integer number) is the rank of this result; '1.23' (or '1.08' or some other number) is the score of this result; and 'my_IR_system1' is the name for your retrieval system. In particular, note that the rank field will be ignored in **trec_eval**; internally ranks are assigned by sorting by the score field with ties broken deterministicly (using file name).\n",
    "\n",
    "**Now here's your first job**\n",
    "\n",
    "1. read `gov.topics` file line by line, \n",
    "2. send query to the elastic search\n",
    "3. write output according the the output format described above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JCxLJVn6r9jC"
   },
   "outputs": [],
   "source": [
    "def read_topic_file(path, encoding = \"ISO-8859-1\"):\n",
    "    '''\n",
    "        reads multiple documents from path\n",
    "        input:\n",
    "            - doc_path : path of document\n",
    "            - encoding: encoding\n",
    "        output: =>\n",
    "            - docs: instances of Doc namedtuple returned as generator\n",
    "    '''\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for doc_path in files:\n",
    "            filename = (root + '/' + doc_path)\n",
    "            fp = io.open(filename, 'r', encoding = encoding)\n",
    "            text = fp.readlines()\n",
    "            fp.close()\n",
    "    return [(t.split(\" \")[0].strip(), \" \".join(t.split(\" \")[1:]).strip()) for t in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-cp6h8-Hr9jC"
   },
   "outputs": [],
   "source": [
    "queries = read_topic_file(\"./practice_data/government/topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G8bZF_WGr9jC",
    "outputId": "22c516fa-1c5e-41e3-ae60-8b7fd099045e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 'mining gold silver coal'),\n",
       " ('2', 'juvenile delinquency'),\n",
       " ('4', 'wireless communications'),\n",
       " ('6', 'physical therapists'),\n",
       " ('7', 'cotton industry'),\n",
       " ('9', 'genealogy searches'),\n",
       " ('10', 'Physical Fitness'),\n",
       " ('14', 'Agricultural biotechnology'),\n",
       " ('16', 'Emergency and disaster preparedness assistance'),\n",
       " ('18', 'Shipwrecks'),\n",
       " ('19', 'Cybercrime, internet fraud, and cyber fraud'),\n",
       " ('22', \"Veteran's Benefits\"),\n",
       " ('24', 'Air Bag Safety'),\n",
       " ('26', 'Nuclear power plants'),\n",
       " ('28', 'Early Childhood Education')]"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0hhajWhr9jD"
   },
   "outputs": [],
   "source": [
    "def search(query_string, es_conn, index_name, operator = \"or\"):\n",
    "    '''\n",
    "        searches for query_string with default search algorithm\n",
    "        input:\n",
    "            - query_string: a query\n",
    "            - es_conn: elasticsearch connection\n",
    "            - index_name: name of index\n",
    "        output:\n",
    "            - a generator of tuple (filename, score)\n",
    "\n",
    "    '''\n",
    "    res = es_conn.search(index = index_name, size = 100,\n",
    "        body = {\n",
    "            \"_source\": [\"filename\"],\n",
    "            \"query\": {\n",
    "                \"match\": {\n",
    "                    \"text\":{\n",
    "                        \"query\": query_string,\n",
    "                        \"operator\" : operator    \n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    for hit in res['hits']['hits']:\n",
    "        filename = hit[\"_source\"][\"filename\"]\n",
    "        score = hit[\"_score\"]\n",
    "        yield (filename, score)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1OHzpNm3r9jE"
   },
   "outputs": [],
   "source": [
    "def write_trec_file(query, res, output_file):\n",
    "    # formatter of searched result\n",
    "    for ranking, match in enumerate(sorted(res, key = lambda x: -x[1])):\n",
    "        output_file.write('{} Q0 {} {} {} {}\\n'.format(\n",
    "            query,\n",
    "            match[0], # filename\n",
    "            ranking,\n",
    "            match[1], # score\n",
    "            \"IR_system\"\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mrGEIm5rr9jE"
   },
   "outputs": [],
   "source": [
    "output_file = open(\"retrieved.txt\",\"w+\")\n",
    "\n",
    "es_conn = Elasticsearch(ES_HOSTS)\n",
    "for query_id, query in queries:\n",
    "    res = search(query, es_conn, EVAL_INDEX_NAME)\n",
    "    write_trec_file(query_id, res, output_file)\n",
    "    \n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76J8Q8FWr9jF"
   },
   "source": [
    "### Exercise 1.3.  Evaluation\n",
    "\n",
    "It's time to run **trec_eval** which compares the qrels file provided in *gov.qrels* with your result file. (hint: adding a **!** and shell commands allow you to execute shell commands in jupyter-notebook, e.g. `!ls`)\n",
    "\n",
    "TREC_EVAL will evaluate the performance of your search engine. To evaluate your search result, you first need two sets of files: the retrieved result file and the ground truth file.\n",
    "Let's say your retrieval result is saved at `retrieved.txt`, and the ground truth file is saved at `gov.qrels`. The performance of your retrieval can be measured via:\n",
    "\n",
    "```\n",
    "./trec_eval.9.0/trec_eval  gov.qrels retrieved.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2wQZAQgr9jF",
    "outputId": "ac37c0b2-0991-48e6-80ba-65fb73062500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runid                 \tall\tIR_system\n",
      "num_q                 \tall\t15\n",
      "num_ret               \tall\t1237\n",
      "num_rel               \tall\t35\n",
      "num_rel_ret           \tall\t17\n",
      "map                   \tall\t0.1121\n",
      "gm_map                \tall\t0.0086\n",
      "Rprec                 \tall\t0.0667\n",
      "bpref                 \tall\t0.0667\n",
      "recip_rank            \tall\t0.1235\n",
      "iprec_at_recall_0.00  \tall\t0.1287\n",
      "iprec_at_recall_0.10  \tall\t0.1287\n",
      "iprec_at_recall_0.20  \tall\t0.1287\n",
      "iprec_at_recall_0.30  \tall\t0.1228\n",
      "iprec_at_recall_0.40  \tall\t0.1220\n",
      "iprec_at_recall_0.50  \tall\t0.1133\n",
      "iprec_at_recall_0.60  \tall\t0.1080\n",
      "iprec_at_recall_0.70  \tall\t0.1080\n",
      "iprec_at_recall_0.80  \tall\t0.0989\n",
      "iprec_at_recall_0.90  \tall\t0.0989\n",
      "iprec_at_recall_1.00  \tall\t0.0989\n",
      "P_5                   \tall\t0.0133\n",
      "P_10                  \tall\t0.0267\n",
      "P_15                  \tall\t0.0356\n",
      "P_20                  \tall\t0.0333\n",
      "P_30                  \tall\t0.0267\n",
      "P_100                 \tall\t0.0113\n",
      "P_200                 \tall\t0.0057\n",
      "P_500                 \tall\t0.0023\n",
      "P_1000                \tall\t0.0011\n"
     ]
    }
   ],
   "source": [
    "! ./trec_eval-master/trec_eval ./practice_data/government/qrels/gov.qrels retrieved.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdF4N0K-r9jF"
   },
   "source": [
    "# Improving the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kc_G-Mkbr9jF"
   },
   "source": [
    "The baseline retrieval that we have proposed before did offer a rather low performance. In order to improve it, we can tune the index setting to include some of the NLP processing that we have learned (e.g., stemming, stopwords, ...)-\n",
    "\n",
    "To that end, review the documentation of analyzer [here](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5jn6jqOr9jG"
   },
   "source": [
    "Although we could generate our own analyzers (as we did in the previous exercises with `my_analyzer`), Elasticsearch provides a set of predefined analyzers for the different languages. More information [here](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-lang-analyzer.html).\n",
    "\n",
    "In particular, we are going to use the `English Analyzer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-TMEOCir9jG"
   },
   "source": [
    "In addition, we can modify the index to use a more sophisticated similarity measure (e.g., `BM25`) than the binary similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZjQ10obr9jG"
   },
   "source": [
    "## Exercise 2.1 English Analyzer + BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gY0klHHlr9jG"
   },
   "source": [
    "Modify the settings to apply the `English Analyzer` and use the `BM25` similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izZGJ3Awr9jG"
   },
   "outputs": [],
   "source": [
    "new_settings = {  \n",
    "# Your code here\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rt0VAAbr9jG"
   },
   "source": [
    "With this new settings we will create a new index, generate a new result file and evaluate it by means of the `trec_eval`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YIjySVctr9jH"
   },
   "outputs": [],
   "source": [
    "ES_HOSTS = ['http://localhost:9200']\n",
    "EVAL_INDEX_NAME = 'government'\n",
    "EVAL_DOCS_PATH = 'practice_data/government/documents'\n",
    "\n",
    "es_conn = Elasticsearch(ES_HOSTS)\n",
    "dataset = read_dataset(EVAL_DOCS_PATH)\n",
    "build_index(es_conn, dataset, EVAL_INDEX_NAME, new_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7htm8TdIr9jH"
   },
   "outputs": [],
   "source": [
    "output_file = open(\"improved_retrieved.txt\",\"w+\")\n",
    "\n",
    "es_conn = Elasticsearch(ES_HOSTS)\n",
    "for query_id, query in queries:\n",
    "    res = search(query, es_conn, EVAL_INDEX_NAME)\n",
    "    write_trec_file(query_id, res, output_file)\n",
    "\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2yclfPoHr9jH"
   },
   "outputs": [],
   "source": [
    "!./trec_eval-master/trec_eval ./practice_data/government/qrels/gov.qrels improved_retrieved.txt"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "day3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
